import json
from pathlib import Path
from collections import defaultdict


class Analyzer:
    @staticmethod
    def find_json_files(base_dir: str) -> list[Path]:
        base_path = Path(base_dir)
        return list(base_path.rglob("*.json"))

    @staticmethod
    def analyze_duplicates(json_files: list[Path]) -> dict:
        name_occurrences = defaultdict(list)

        for file_path in json_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
            except Exception as e:
                print(f"[BÅ‚Ä…d] Nie udaÅ‚o siÄ™ wczytaÄ‡ {file_path}: {e}")
                continue

            parts = data.get("parts", [])
            for part_idx, part in enumerate(parts):
                chapters = part.get("chapters", [])
                for chap_idx, chapter in enumerate(chapters):
                    components = chapter.get("components", [])
                    for comp_idx, component in enumerate(components):
                        if component.get("kind") == "component":
                            name = component.get("name")
                            if name:
                                name_occurrences[name].append({
                                    "file": str(file_path),
                                    "part_index": part_idx,
                                    "chapter_index": chap_idx,
                                    "component_index": comp_idx
                                })

        return {
            name: locations
            for name, locations in name_occurrences.items()
            if len(locations) > 1
        }

    @staticmethod
    def report_duplicates(base_dir: str):
        files = Analyzer.find_json_files(base_dir)
        duplicates = Analyzer.analyze_duplicates(files)

        if not duplicates:
            print("âœ… Brak duplikatÃ³w komponentÃ³w.")
            return

        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘      âš ï¸  Znaleziono duplikaty komponentÃ³w (name)     â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

        for name, occurrences in duplicates.items():
            print(f"ğŸ“› Name: {name}")
            for occ in occurrences:
                print(f"   â”œâ”€ Plik: {occ['file']}")
                location = f"part[{occ['part_index']}], chapter[{occ['chapter_index']}], component[{occ['component_index']}]"
                print(f"   â””â”€ Lokalizacja: {location}")
            print("â”€" * 60)

        print(f"\nğŸ” ÅÄ…cznie zduplikowanych nazw: {len(duplicates)}")


if __name__ == "__main__":
    Analyzer.report_duplicates("./output/json")
